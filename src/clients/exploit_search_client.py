"""
VIPER - Public Exploit Search Client

This module searches for publicly available exploits for CVEs from:
1. Exploit-DB
2. GitHub Repositories
"""
import json
import logging
import os
import sys
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, Union

import requests
from tenacity import retry, retry_if_exception_type, stop_after_attempt, wait_exponential

# Add the project root directory to the path to import modules
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.utils.config import (
    get_exploit_db_api_url,
    get_exploit_search_max_results,
    get_github_api_url,
    get_github_token,
)

# Set up logging
logger = logging.getLogger(__name__)

# Simple in-memory cache for exploit search results (TTL: 1 hour)
_exploit_cache = {}
_cache_ttl = 3600  # seconds


def _get_from_cache(cve_id: str) -> Optional[List[Dict[str, Any]]]:
    """Get exploit data from cache if it exists and is fresh"""
    if cve_id in _exploit_cache:
        timestamp, data = _exploit_cache[cve_id]
        if time.time() - timestamp < _cache_ttl:
            logger.debug(f"Cache hit for {cve_id}")
            return data
    return None


def _add_to_cache(cve_id: str, data: List[Dict[str, Any]]) -> None:
    """Add exploit data to cache with current timestamp"""
    _exploit_cache[cve_id] = (time.time(), data)
    logger.debug(f"Added {cve_id} to cache with {len(data)} exploits")


@retry(
    retry=retry_if_exception_type((requests.RequestException, ConnectionError, json.JSONDecodeError)),
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=30),
)
def search_exploit_db(cve_id: str) -> List[Dict[str, Any]]:
    """
    Search Exploit-DB for exploits related to a CVE

    Args:
        cve_id: The CVE ID to search for

    Returns:
        List of dictionaries with exploit information
    """
    exploits = []
    api_url = get_exploit_db_api_url()

    try:
        # Exploit-DB's API endpoint with CVE filter
        url = f"{api_url}/search"
        params = {"cve": cve_id.replace("CVE-", "")}

        logger.info(f"Searching Exploit-DB for {cve_id}")
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()

        data = response.json()

        if "data" in data and isinstance(data["data"], list):
            for exploit in data["data"]:
                # Extract relevant fields
                exploit_info = {
                    "source": "Exploit-DB",
                    "title": exploit.get("title", "Unknown Title"),
                    "url": f"https://www.exploit-db.com/exploits/{exploit.get('id', 'unknown')}",
                    "type": exploit.get("type", "Unknown"),
                    "date_published": exploit.get("date_published", "Unknown"),
                    "exploit_id": exploit.get("id"),
                }
                exploits.append(exploit_info)

        logger.info(f"Found {len(exploits)} exploits on Exploit-DB for {cve_id}")

    except requests.RequestException as e:
        logger.error(f"Error searching Exploit-DB: {str(e)}")
        # Re-raise for retry mechanism
        raise
    except json.JSONDecodeError as e:
        logger.error(f"Error parsing Exploit-DB response: {str(e)}")
        raise
    except Exception as e:
        logger.error(f"Unexpected error searching Exploit-DB: {str(e)}")

    return exploits


@retry(
    retry=retry_if_exception_type((requests.RequestException, ConnectionError, json.JSONDecodeError)),
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=30),
)
def search_github(cve_id: str) -> List[Dict[str, Any]]:
    """
    Search GitHub for exploits related to a CVE

    Args:
        cve_id: The CVE ID to search for

    Returns:
        List of dictionaries with exploit information
    """
    exploits = []
    github_token = get_github_token()
    api_url = get_github_api_url()
    max_results = get_exploit_search_max_results()

    if not github_token:
        logger.warning("GitHub token not found. Skipping GitHub search.")
        return exploits

    try:
        # Search for repositories with exploit code for the CVE
        # We use multiple search terms to improve results
        search_queries = [f"{cve_id} exploit", f"{cve_id} PoC", f"{cve_id} proof of concept"]

        headers = {
            "Accept": "application/vnd.github.v3+json",
            "Authorization": f"token {github_token}",
        }

        for query in search_queries:
            logger.info(f"Searching GitHub for: {query}")

            # Search repositories
            repo_url = f"{api_url}/search/repositories"
            repo_params = {"q": query, "sort": "updated", "order": "desc", "per_page": max_results}

            repo_response = requests.get(repo_url, headers=headers, params=repo_params, timeout=10)
            repo_response.raise_for_status()
            repo_data = repo_response.json()

            for repo in repo_data.get("items", []):
                # Check if this is likely an exploit/PoC repository
                name = repo.get("name", "").lower()
                description = repo.get("description", "").lower() if repo.get("description") else ""

                # Look for keywords suggesting this is an exploit repo
                is_exploit = any(
                    keyword in name or keyword in description
                    for keyword in ["exploit", "poc", "proof", "vulnerability", "cve-"]
                )

                if is_exploit:
                    exploit_info = {
                        "source": "GitHub",
                        "title": repo.get("name", "Unknown Repository"),
                        "url": repo.get("html_url", ""),
                        "type": "Repository",
                        "date_published": repo.get("created_at", "Unknown"),
                        "description": repo.get("description", "No description"),
                        "stars": repo.get("stargazers_count", 0),
                    }

                    # Only add if we don't already have this URL
                    if not any(e["url"] == exploit_info["url"] for e in exploits):
                        exploits.append(exploit_info)

            # Avoid rate limiting
            time.sleep(1)

            # Also search code
            code_url = f"{api_url}/search/code"
            code_params = {"q": query, "sort": "indexed", "order": "desc", "per_page": max_results}

            code_response = requests.get(code_url, headers=headers, params=code_params, timeout=10)
            code_response.raise_for_status()
            code_data = code_response.json()

            for code_item in code_data.get("items", []):
                # Extract code information
                repo_name = code_item.get("repository", {}).get("full_name", "Unknown")
                path = code_item.get("path", "Unknown")

                exploit_info = {
                    "source": "GitHub",
                    "title": f"{repo_name}: {path}",
                    "url": code_item.get("html_url", ""),
                    "type": "Code",
                    "date_published": "Unknown",  # GitHub API doesn't provide creation date for code search results
                }

                # Only add if we don't already have this URL
                if not any(e["url"] == exploit_info["url"] for e in exploits):
                    exploits.append(exploit_info)

            # Avoid rate limiting
            time.sleep(1)

        logger.info(f"Found {len(exploits)} potential exploits on GitHub for {cve_id}")

    except requests.RequestException as e:
        logger.error(f"Error searching GitHub: {str(e)}")
        raise
    except json.JSONDecodeError as e:
        logger.error(f"Error parsing GitHub response: {str(e)}")
        raise
    except Exception as e:
        logger.error(f"Unexpected error searching GitHub: {str(e)}")

    return exploits


def find_public_exploits(cve_id: str) -> Optional[List[Dict[str, Any]]]:
    """
    Search for publicly available exploits for a given CVE ID

    Args:
        cve_id: The CVE ID to search for

    Returns:
        List of dictionaries containing exploit information, or None if error occurs
    """
    if not cve_id or not cve_id.startswith("CVE-"):
        logger.error(f"Invalid CVE ID: {cve_id}")
        return None

    # Check cache first
    cached_result = _get_from_cache(cve_id)
    if cached_result is not None:
        return cached_result

    try:
        all_exploits = []

        # Get configuration for exploit search sources
        exploit_db_url = get_exploit_db_api_url()
        github_token = get_github_token()

        # Search Exploit-DB only if URL is configured
        if exploit_db_url:
            logger.info(f"Searching Exploit-DB for {cve_id}")
            exploit_db_results = search_exploit_db(cve_id)
            all_exploits.extend(exploit_db_results)
        else:
            logger.info(f"Skipping Exploit-DB search for {cve_id} - No API URL configured")

        # Search GitHub only if token is configured
        if github_token:
            logger.info(f"Searching GitHub for {cve_id}")
            github_results = search_github(cve_id)
            all_exploits.extend(github_results)
        else:
            logger.info(f"Skipping GitHub search for {cve_id} - No API token configured")

        # If no sources are configured, log a warning
        if not exploit_db_url and not github_token:
            logger.warning(
                f"No exploit search sources configured for {cve_id}. Configure EXPLOIT_DB_API_URL or GITHUB_TOKEN."
            )
            return []

        # Sort results by date published (if available)
        # Handle the datetime comparison safely
        def get_sort_key(exploit):
            date_published = exploit.get("date_published", "Unknown")
            if isinstance(date_published, str) and date_published != "Unknown":
                try:
                    # Remove timezone information if present to ensure all naive datetimes
                    if "Z" in date_published:
                        # Convert to naive datetime
                        return datetime.fromisoformat(date_published.replace("Z", ""))
                    elif "+" in date_published or "-" in date_published and "T" in date_published:
                        # For dates with timezone info, convert to naive datetime
                        dt = datetime.fromisoformat(date_published)
                        return dt.replace(tzinfo=None)
                    else:
                        # Already a naive datetime string
                        return datetime.fromisoformat(date_published)
                except (ValueError, TypeError):
                    # If we can't parse it, use minimum datetime
                    return datetime.min
            return datetime.min

        all_exploits.sort(key=get_sort_key, reverse=True)

        # Add to cache
        _add_to_cache(cve_id, all_exploits)

        return all_exploits

    except Exception as e:
        logger.error(f"Error finding public exploits for {cve_id}: {str(e)}")
        return None
